# Makefile: GestiÃ³n de K8s multi-cluster (Dev/Pro)
# Variables Globales
DEV=k3d-dev-cluster
PRO=k3d-prod-cluster
IMG ?= app-image:v1

.PHONY: clusters clean switch-dev switch-pro import deploy-dev deploy-pro \
        grafana-dev grafana-pro prometheus-dev prometheus-pro \
        test-dev test-pro stop-db-dev start-db-dev stop-db-pro start-db-pro \
        stop-minio-dev start-minio-dev stop-minio-pro start-minio-pro \
        trigger-alert-dev resolve-alert-dev trigger-alert-pro resolve-alert-pro

# ==============================================================================
# ğŸ› ï¸ GESTIÃ“N DE CLUSTERS (Setup Inicial)
# ==============================================================================

clusters: ## 1. Crea ambos clusters (dev:8081, pro:8080)
	k3d cluster create dev-cluster --port "8081:80@loadbalancer" --servers 1 --agents 0 --wait
	k3d cluster create prod-cluster --port "8080:80@loadbalancer" --servers 1 --agents 1 --wait
	@echo "âœ… Clusters listos."

clean: ## Borra todo (Clusters y Datos)
	k3d cluster delete dev-cluster prod-cluster

switch-dev: ## ğŸ”„ Cambia contexto local a DEV
	kubectl config use-context $(DEV)
	kubectl config set-context --current --namespace=dev
	@echo "ğŸ”„ EstÃ¡s en DEV"

switch-pro: ## ğŸ”„ Cambia contexto local a PRO
	kubectl config use-context $(PRO)
	kubectl config set-context --current --namespace=pro
	@echo "ğŸ”„ EstÃ¡s en PRO"

current-context: ## Muestra contexto actual
	kubectl config current-context

import: ## Construye e importa imagen Docker a k3d
	docker build -t $(IMG) ./app
	k3d image import $(IMG) -c dev-cluster -c prod-cluster

# ==============================================================================
# ğŸš€ DESPLIEGUES (APP + INFRA)
# ==============================================================================

deploy-dev: import ## 2. Despliega DEV (sin Redis, 2 rÃ©plicas)
	kubectl config use-context $(DEV)
	# Namespace y Config
	kubectl create ns dev --dry-run=client -o yaml | kubectl apply -f -
	kubectl apply -n dev -f k8s/environments/dev/config.yaml -f k8s/environments/dev/secrets.yaml
	# Plataforma Base
	kubectl apply -n dev -f k8s/base/platform/postgres.yaml -f k8s/base/platform/db-init.yaml -f k8s/base/platform/minio.yaml -f k8s/base/platform/minio-init.yaml
	# App y Red
	kubectl apply -n dev -f k8s/base/app/deployment.yaml -f k8s/base/app/service.yaml -f k8s/environments/dev/ingress.yaml
	kubectl set image deployment/app-deployment app-container=$(IMG) -n dev
	kubectl scale deployment app-deployment --replicas=2 -n dev
	# MonitorizaciÃ³n
	$(MAKE) deploy-monitoring-dev
	@echo "âœ… DEV listo. ğŸŒ URL: http://app.dev.localhost:8081"

deploy-pro: import ## 2. Despliega PRO (con Redis, 4 rÃ©plicas)
	kubectl config use-context $(PRO)
	# Namespace y Config
	kubectl create ns pro --dry-run=client -o yaml | kubectl apply -f -
	kubectl apply -n pro -f k8s/environments/pro/config.yaml -f k8s/environments/pro/secrets.yaml
	# Plataforma Base
	kubectl apply -n pro -f k8s/base/platform/postgres.yaml -f k8s/base/platform/db-init.yaml -f k8s/base/platform/redis.yaml -f k8s/base/platform/minio.yaml -f k8s/base/platform/minio-init.yaml
	# App y Red
	kubectl apply -n pro -f k8s/base/app/deployment.yaml -f k8s/base/app/service.yaml -f k8s/environments/pro/ingress.yaml
	kubectl set image deployment/app-deployment app-container=$(IMG) -n pro
	kubectl scale deployment app-deployment --replicas=4 -n pro
	# MonitorizaciÃ³n
	$(MAKE) deploy-monitoring-pro
	@echo "âœ… PRO listo. ğŸŒ URL: http://app.pro.localhost:8080"

# --- Subtareas de MonitorizaciÃ³n ---

deploy-monitoring-dev:
	kubectl config use-context $(DEV)
	kubectl create ns monitoring --dry-run=client -o yaml | kubectl apply -f -
	kubectl apply -f k8s/environments/dev/monitoring/secrets.yaml
	helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
	helm repo update
	helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
		--namespace monitoring \
		--set grafana.admin.existingSecret=grafana-admin-credentials \
		--set grafana.admin.userKey=admin-user \
		--set grafana.admin.passwordKey=admin-password
	kubectl apply -f k8s/environments/dev/monitoring/service-monitor.yaml
	kubectl apply -f k8s/environments/dev/monitoring/alert-rules.yaml

deploy-monitoring-pro:
	kubectl config use-context $(PRO)
	kubectl create ns monitoring --dry-run=client -o yaml | kubectl apply -f -
	kubectl apply -f k8s/environments/pro/monitoring/secrets.yaml
	helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
	helm repo update
	helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
		--namespace monitoring \
		--set grafana.admin.existingSecret=grafana-admin-credentials \
		--set grafana.admin.userKey=admin-user \
		--set grafana.admin.passwordKey=admin-password
	kubectl apply -f k8s/environments/pro/monitoring/service-monitor.yaml
	kubectl apply -f k8s/environments/pro/monitoring/alert-rules.yaml

# ==============================================================================
# ğŸ” ACCEOS Y LOGS
# ==============================================================================

logs-dev: ## Logs de la App en DEV
	kubectl logs -n dev -l app=app --context $(DEV)

logs-pro: ## Logs de la App en PRO
	kubectl logs -n pro -l app=app --context $(PRO)

grafana-dev: ## ğŸ“Š Acceso Grafana DEV (http://localhost:3001)
	@echo "ğŸ“Š Abriendo Grafana DEV (User: admin)..."
	kubectl --context $(DEV) -n monitoring port-forward svc/kube-prometheus-stack-grafana 3001:80

grafana-pro: ## ğŸ“Š Acceso Grafana PRO (http://localhost:3000)
	@echo "ğŸ“Š Abriendo Grafana PRO (User: admin)..."
	kubectl --context $(PRO) -n monitoring port-forward svc/kube-prometheus-stack-grafana 3000:80

prometheus-dev: ## ğŸ“ˆ Acceso Prometheus DEV (http://localhost:9091)
	kubectl --context $(DEV) -n monitoring port-forward svc/kube-prometheus-stack-prometheus 9091:9090

prometheus-pro: ## ğŸ“ˆ Acceso Prometheus PRO (http://localhost:9090)
	kubectl --context $(PRO) -n monitoring port-forward svc/kube-prometheus-stack-prometheus 9090:9090

tunnel-dev:; kubectl port-forward --context $(DEV) -n dev svc/app-service 9001:80
tunnel-pro:; kubectl port-forward --context $(PRO) -n pro svc/app-service 9002:80

# ==============================================================================
# ğŸ§ª TESTS INTEGRACIÃ“N
# ==============================================================================

test-dev: ## Ejecuta tests contra entorno DEV
	@echo "ğŸ§ª Testeando DEV..."
	pip install -q -r tests/requirements.txt
	TEST_URL=http://app.dev.localhost:8081 pytest tests/ -v

test-pro: ## Ejecuta tests contra entorno PRO
	@echo "ğŸ§ª Testeando PRO..."
	pip install -q -r tests/requirements.txt
	TEST_URL=http://app.pro.localhost:8080 pytest tests/ -v

# ==============================================================================
# ğŸ’¥ CHAOS ENGINEERING (SimulaciÃ³n de Fallos)
# ==============================================================================

# --- Database Chaos ---
stop-db-dev: ## ğŸ›‘ Detiene BD en DEV
	kubectl scale deployment postgres-deployment --replicas=0 -n dev --context $(DEV)

start-db-dev: ## â–¶ï¸ Inicia BD en DEV
	kubectl scale deployment postgres-deployment --replicas=1 -n dev --context $(DEV)

stop-db-pro: ## ğŸ›‘ Detiene BD en PRO
	kubectl scale deployment postgres-deployment --replicas=0 -n pro --context $(PRO)

start-db-pro: ## â–¶ï¸ Inicia BD en PRO
	kubectl scale deployment postgres-deployment --replicas=1 -n pro --context $(PRO)

# --- MinIO Chaos ---
stop-minio-dev: ## ğŸ›‘ Detiene MinIO en DEV (Favicon error)
	kubectl scale deployment minio-deployment --replicas=0 -n dev --context $(DEV)

start-minio-dev: ## â–¶ï¸ Inicia MinIO en DEV
	kubectl scale deployment minio-deployment --replicas=1 -n dev --context $(DEV)

stop-minio-pro: ## ğŸ›‘ Detiene MinIO en PRO
	kubectl scale deployment minio-deployment --replicas=0 -n pro --context $(PRO)

start-minio-pro: ## â–¶ï¸ Inicia MinIO en PRO
	kubectl scale deployment minio-deployment --replicas=1 -n pro --context $(PRO)

# --- App Scalability Chaos ---
trigger-alert-dev: ## âš ï¸  Provoca alerta (1 RÃ©plica) en DEV
	kubectl scale deployment app-deployment --replicas=1 -n dev --context $(DEV)

resolve-alert-dev: ## âœ… Resuelve alerta (2 RÃ©plicas) en DEV
	kubectl scale deployment app-deployment --replicas=2 -n dev --context $(DEV)

trigger-alert-pro: ## âš ï¸  Provoca alerta (1 RÃ©plica) en PRO
	kubectl scale deployment app-deployment --replicas=1 -n pro --context $(PRO)

resolve-alert-pro: ## âœ… Resuelve alerta (4 RÃ©plicas) en PRO
	kubectl scale deployment app-deployment --replicas=4 -n pro --context $(PRO)
